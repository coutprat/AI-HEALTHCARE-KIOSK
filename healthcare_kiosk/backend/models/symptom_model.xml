<?xml version="1.0"?>
<net name="main_graph" version="11">
	<layers>
		<layer id="0" name="input" type="Parameter" version="opset1">
			<data shape="1,55" element_type="f32" />
			<output>
				<port id="0" precision="FP32" names="input">
					<dim>1</dim>
					<dim>55</dim>
				</port>
			</output>
		</layer>
		<layer id="1" name="classifier.0.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="64, 55" offset="0" size="7040" />
			<output>
				<port id="0" precision="FP16" names="classifier.0.weight">
					<dim>64</dim>
					<dim>55</dim>
				</port>
			</output>
		</layer>
		<layer id="2" name="classifier.0.weight" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>64</dim>
					<dim>55</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>55</dim>
				</port>
			</output>
		</layer>
		<layer id="3" name="/classifier/classifier.0/Gemm/WithoutBiases" type="MatMul" version="opset1">
			<data transpose_a="false" transpose_b="true" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>55</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>64</dim>
					<dim>55</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="4" name="Constant_1586_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 64" offset="7040" size="128" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="5" name="Constant_1586" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="6" name="/classifier/classifier.0/Gemm" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="/classifier/classifier.0/Gemm_output_0">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="7" name="/classifier/classifier.1/Relu" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="/classifier/classifier.1/Relu_output_0">
					<dim>1</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="8" name="classifier.3.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="32, 64" offset="7168" size="4096" />
			<output>
				<port id="0" precision="FP16" names="classifier.3.weight">
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="9" name="classifier.3.weight" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</output>
		</layer>
		<layer id="10" name="/classifier/classifier.3/Gemm/WithoutBiases" type="MatMul" version="opset1">
			<data transpose_a="false" transpose_b="true" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>64</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>32</dim>
					<dim>64</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="11" name="Constant_1587_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 32" offset="11264" size="64" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="12" name="Constant_1587" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="13" name="/classifier/classifier.3/Gemm" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="/classifier/classifier.3/Gemm_output_0">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="14" name="/classifier/classifier.4/Relu" type="ReLU" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32" names="/classifier/classifier.4/Relu_output_0">
					<dim>1</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="15" name="classifier.5.weight_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="16, 32" offset="11328" size="1024" />
			<output>
				<port id="0" precision="FP16" names="classifier.5.weight">
					<dim>16</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="16" name="classifier.5.weight" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>16</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>32</dim>
				</port>
			</output>
		</layer>
		<layer id="17" name="/classifier/classifier.5/Gemm/WithoutBiases" type="MatMul" version="opset1">
			<data transpose_a="false" transpose_b="true" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>32</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>16</dim>
					<dim>32</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="18" name="Constant_1588_compressed" type="Const" version="opset1">
			<data element_type="f16" shape="1, 16" offset="12352" size="32" />
			<output>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="19" name="Constant_1588" type="Convert" version="opset1">
			<data destination_type="f32" />
			<rt_info>
				<attribute name="decompression" version="0" />
			</rt_info>
			<input>
				<port id="0" precision="FP16">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="20" name="output" type="Add" version="opset1">
			<data auto_broadcast="numpy" />
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
				</port>
				<port id="1" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</input>
			<output>
				<port id="2" precision="FP32" names="output">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</output>
		</layer>
		<layer id="21" name="output/sink_port_0" type="Result" version="opset1">
			<input>
				<port id="0" precision="FP32">
					<dim>1</dim>
					<dim>16</dim>
				</port>
			</input>
		</layer>
	</layers>
	<edges>
		<edge from-layer="0" from-port="0" to-layer="3" to-port="0" />
		<edge from-layer="1" from-port="0" to-layer="2" to-port="0" />
		<edge from-layer="2" from-port="1" to-layer="3" to-port="1" />
		<edge from-layer="3" from-port="2" to-layer="6" to-port="0" />
		<edge from-layer="4" from-port="0" to-layer="5" to-port="0" />
		<edge from-layer="5" from-port="1" to-layer="6" to-port="1" />
		<edge from-layer="6" from-port="2" to-layer="7" to-port="0" />
		<edge from-layer="7" from-port="1" to-layer="10" to-port="0" />
		<edge from-layer="8" from-port="0" to-layer="9" to-port="0" />
		<edge from-layer="9" from-port="1" to-layer="10" to-port="1" />
		<edge from-layer="10" from-port="2" to-layer="13" to-port="0" />
		<edge from-layer="11" from-port="0" to-layer="12" to-port="0" />
		<edge from-layer="12" from-port="1" to-layer="13" to-port="1" />
		<edge from-layer="13" from-port="2" to-layer="14" to-port="0" />
		<edge from-layer="14" from-port="1" to-layer="17" to-port="0" />
		<edge from-layer="15" from-port="0" to-layer="16" to-port="0" />
		<edge from-layer="16" from-port="1" to-layer="17" to-port="1" />
		<edge from-layer="17" from-port="2" to-layer="20" to-port="0" />
		<edge from-layer="18" from-port="0" to-layer="19" to-port="0" />
		<edge from-layer="19" from-port="1" to-layer="20" to-port="1" />
		<edge from-layer="20" from-port="2" to-layer="21" to-port="0" />
	</edges>
	<rt_info>
		<Runtime_version value="2024.6.0-17404-4c0f47d2335-releases/2024/6" />
		<conversion_parameters>
			<is_python_object value="False" />
		</conversion_parameters>
	</rt_info>
</net>
